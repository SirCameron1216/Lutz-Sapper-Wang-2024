{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rhelogy Models for Predicting Values of UV-curable Inkjet Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import time\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import xgboost\n",
    "import pickle\n",
    "\n",
    "from numpy import arange\n",
    "from pandas import read_csv\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn_genetic.space import Integer, Categorical, Continuous\n",
    "from mapie.regression import MapieRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocky = pd.read_excel('FINAL-trainingset.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Surface Tension', 'Viscosity', 'Density'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocky.columns[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Surface Tension      MW     AMW      Sv      Se      Sp      Si     Mv  \\\n",
      "0                NaN   78.50  11.214   4.596   7.418   4.835   7.984  0.657   \n",
      "1              25.90  137.03   9.788   7.659  13.647   9.159  15.918  0.547   \n",
      "2              25.26  123.00  11.182   6.132  10.764   7.398  12.502  0.557   \n",
      "3              24.93   74.14   4.943   7.349  14.745   8.262  17.285  0.490   \n",
      "4              23.18   92.58   6.613   7.461  13.742   8.665  16.020  0.533   \n",
      "..               ...     ...     ...     ...     ...     ...     ...    ...   \n",
      "265              NaN  267.83  53.566   4.687   4.905   7.841   5.272  0.937   \n",
      "266            47.10   90.14   5.634   8.064  16.073   8.716  18.495  0.504   \n",
      "267            44.40  207.07  11.504  13.132  17.764  14.398  19.502  0.730   \n",
      "268            31.10  390.62   5.918  36.868  65.098  40.285  74.726  0.559   \n",
      "269            26.70   53.07   7.581   4.548   6.985   4.767   7.914  0.650   \n",
      "\n",
      "        Me     Mp  ...  F08_C-C_  F08_C-N_  F08_C-O_  F08_O-O_  F09_C-C_  \\\n",
      "0    1.060  0.691  ...         0         0         0         0         0   \n",
      "1    0.975  0.654  ...         0         0         0         0         0   \n",
      "2    0.978  0.673  ...         0         0         0         0         0   \n",
      "3    0.983  0.551  ...         0         0         0         0         0   \n",
      "4    0.982  0.619  ...         0         0         0         0         0   \n",
      "..     ...    ...  ...       ...       ...       ...       ...       ...   \n",
      "265  0.981  1.568  ...         0         0         0         0         0   \n",
      "266  1.005  0.545  ...         0         0         0         0         0   \n",
      "267  0.987  0.800  ...         0         0         0         0         0   \n",
      "268  0.986  0.610  ...        24         0        10         0        19   \n",
      "269  0.998  0.681  ...         0         0         0         0         0   \n",
      "\n",
      "     F09_C-O_  F09_O-O_  F10_C-C_  F10_C-O_  F10_O-O_  \n",
      "0           0         0         0         0         0  \n",
      "1           0         0         0         0         0  \n",
      "2           0         0         0         0         0  \n",
      "3           0         0         0         0         0  \n",
      "4           0         0         0         0         0  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "265         0         0         0         0         0  \n",
      "266         0         0         0         0         0  \n",
      "267         0         0         0         0         0  \n",
      "268         8         0        16         4         0  \n",
      "269         0         0         0         0         0  \n",
      "\n",
      "[270 rows x 1059 columns]\n"
     ]
    }
   ],
   "source": [
    "rocky = rocky.drop(columns=['ID','Molecule_Name','SMILES'])\n",
    "#rocky = rocky.drop(columns=['Surface Tension'])\n",
    "rocky = rocky.drop(columns=['Viscosity'])\n",
    "rocky = rocky.drop(columns=['Density'])\n",
    "print(rocky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 1059)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocky.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rocky1 = rocky.dropna(axis=0, subset=['Density'])\n",
    "#rocky1 = rocky.dropna(axis=0, subset=['Viscosity'])\n",
    "rocky1 = rocky.dropna(axis=0, subset=['Surface Tension'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surface Tension</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>...</th>\n",
       "      <th>F08_C-C_</th>\n",
       "      <th>F08_C-N_</th>\n",
       "      <th>F08_C-O_</th>\n",
       "      <th>F08_O-O_</th>\n",
       "      <th>F09_C-C_</th>\n",
       "      <th>F09_C-O_</th>\n",
       "      <th>F09_O-O_</th>\n",
       "      <th>F10_C-C_</th>\n",
       "      <th>F10_C-O_</th>\n",
       "      <th>F10_O-O_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.90</td>\n",
       "      <td>137.03</td>\n",
       "      <td>9.788</td>\n",
       "      <td>7.659</td>\n",
       "      <td>13.647</td>\n",
       "      <td>9.159</td>\n",
       "      <td>15.918</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.654</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.26</td>\n",
       "      <td>123.00</td>\n",
       "      <td>11.182</td>\n",
       "      <td>6.132</td>\n",
       "      <td>10.764</td>\n",
       "      <td>7.398</td>\n",
       "      <td>12.502</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.673</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.93</td>\n",
       "      <td>74.14</td>\n",
       "      <td>4.943</td>\n",
       "      <td>7.349</td>\n",
       "      <td>14.745</td>\n",
       "      <td>8.262</td>\n",
       "      <td>17.285</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.551</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.18</td>\n",
       "      <td>92.58</td>\n",
       "      <td>6.613</td>\n",
       "      <td>7.461</td>\n",
       "      <td>13.742</td>\n",
       "      <td>8.665</td>\n",
       "      <td>16.020</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.619</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.73</td>\n",
       "      <td>120.64</td>\n",
       "      <td>6.032</td>\n",
       "      <td>10.515</td>\n",
       "      <td>19.509</td>\n",
       "      <td>12.188</td>\n",
       "      <td>22.850</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.609</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1059 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Surface Tension      MW     AMW      Sv      Se      Sp      Si     Mv  \\\n",
       "1            25.90  137.03   9.788   7.659  13.647   9.159  15.918  0.547   \n",
       "2            25.26  123.00  11.182   6.132  10.764   7.398  12.502  0.557   \n",
       "3            24.93   74.14   4.943   7.349  14.745   8.262  17.285  0.490   \n",
       "4            23.18   92.58   6.613   7.461  13.742   8.665  16.020  0.533   \n",
       "5            25.73  120.64   6.032  10.515  19.509  12.188  22.850  0.526   \n",
       "\n",
       "      Me     Mp  ...  F08_C-C_  F08_C-N_  F08_C-O_  F08_O-O_  F09_C-C_  \\\n",
       "1  0.975  0.654  ...         0         0         0         0         0   \n",
       "2  0.978  0.673  ...         0         0         0         0         0   \n",
       "3  0.983  0.551  ...         0         0         0         0         0   \n",
       "4  0.982  0.619  ...         0         0         0         0         0   \n",
       "5  0.975  0.609  ...         0         0         0         0         0   \n",
       "\n",
       "   F09_C-O_  F09_O-O_  F10_C-C_  F10_C-O_  F10_O-O_  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "5         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 1059 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocky1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Wrangle Data\n",
    "#d_X = rocky1.drop(columns=['Density'])\n",
    "#d_X = rocky1.drop(columns=['Viscosity'])\n",
    "d_X = rocky1.drop(columns=['Surface Tension'])\n",
    "#d_y = rocky1['Density']\n",
    "#d_y = rocky1['Viscosity']\n",
    "d_y = rocky1['Surface Tension']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(d_X, d_y, test_size = 0.25, random_state = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "train_Xsc = scaler.fit_transform(train_X)\n",
    "#test_Xsc = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partial Least Squares\n",
    "# pls = PLSRegression(n_components=5)  \n",
    "# X_train_pls = pls.fit_transform(train_Xsc, train_y)[0]\n",
    "# X_test_pls = pls.transform(test_Xsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principle Component Analysis\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(train_Xsc)\n",
    "#X_test_pca = pca.transform(test_Xsc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_var_ratio = pca.explained_variance_ratio_\n",
    "cumulative_var_ratio = np.cumsum(explained_var_ratio)\n",
    "\n",
    "plt.plot(range(1, len(cumulative_var_ratio) + 1), cumulative_var_ratio, marker='o')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio vs. Number of Principal Components')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = ElasticNet(random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_hyperparam = {\n",
    "    'alpha': np.concatenate([np.logspace(-4, 1, 10)]),\n",
    "    'l1_ratio': np.concatenate([np.linspace(0, 1, 11)]),\n",
    "    'max_iter': [1000, 2000],  # Including 1000 and a value close to it for variety\n",
    "    'selection': ['cyclic', 'random'],  # Including both 'cyclic' and 'random'\n",
    "    'tol': [0.001, 0.0001, 0.01] \n",
    "}\n",
    "print(enet_hyperparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_model_cv = GridSearchCV(estimator=enet,\n",
    "                       param_grid=enet_hyperparam,\n",
    "                       scoring='r2',\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1,\n",
    "                       cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enet_model_cv = BayesSearchCV(enet, \n",
    "#                               enet_hyperparam,\n",
    "#                               n_iter=100,\n",
    "#                               cv=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enet_model_cv = GASearchCV(estimator = enet, \n",
    "#                                 cv=3,\n",
    "#                                 scoring= 'r2',  \n",
    "#                                 population_size=20,\n",
    "#                                 generations=35,\n",
    "#                                 param_grid = enet_hyperparam,\n",
    "#                                 verbose = False,\n",
    "#                                 n_jobs = -1,\n",
    "#                                 keep_top_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "\n",
    "enet_model_cv.fit(train_Xsc, train_y)\n",
    "#enet_model_cv.fit(X_train_pls, train_y)\n",
    "#enet_model_cv.fit(X_train_pca, train_y)\n",
    "\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial score: ', enet_model_cv.best_score_)\n",
    "print('Initial parameters: ', enet_model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_enet = enet_model_cv.best_estimator_\n",
    "density_pickle = open('density_EN_Full.pickle', 'wb') \n",
    "pickle.dump(best_enet, density_pickle) \n",
    "density_pickle.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Test Set\n",
    "dy_pred_en = enet_model_cv.predict(test_Xsc)\n",
    "#dy_pred_en = enet_model_cv.predict(X_test_pls)\n",
    "#dy_pred_en = enet_model_cv.predict(X_test_pca)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_en = sklearn.metrics.r2_score(test_y, dy_pred_en)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_en)\n",
    "\n",
    "RMSE_test_density_en = sklearn.metrics.mean_squared_error(test_y, dy_pred_en, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_residuals = test_y - dy_pred_en\n",
    "\n",
    "# Create a DataFrame for the residuals\n",
    "residuals_df = pd.DataFrame({'Residuals': en_residuals})\n",
    "\n",
    "# Find the index of the highest residual\n",
    "max_residual_index = residuals_df['Residuals'].idxmax()\n",
    "\n",
    "# Drop the row with the highest residual\n",
    "residuals_df = residuals_df.drop(index=max_residual_index)\n",
    "\n",
    "residuals_df.hist(bins=25, figsize=(12,8), color=\"maroon\")\n",
    "\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Number of Test Datapoints')\n",
    "plt.title('Distribution of Residuals: Elastic Net')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "feature_names = pd.DataFrame(d_X).columns\n",
    "perm_importance = permutation_importance(best_enet, test_Xsc, test_y, n_repeats=30, random_state=42)\n",
    "\n",
    "# Extract importance scores and their standard deviations\n",
    "importances_mean = perm_importance.importances_mean\n",
    "importances_std = perm_importance.importances_std\n",
    "\n",
    "# Get the indices of the top 10 features by importance\n",
    "top_10_indices = np.argsort(importances_mean)[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 10 features\n",
    "top_10_feature_names = [feature_names[i] for i in top_10_indices]\n",
    "\n",
    "# Print the top 10 features with their importance and confidence intervals\n",
    "print(\"Top 10 feature importances with confidence intervals:\")\n",
    "for i in top_10_indices:\n",
    "    if importances_mean[i] - 2 * importances_std[i] > 0:\n",
    "        print(f\"{feature_names[i]:<8} {importances_mean[i]:.3f} +/- {importances_std[i]:.3f}\")\n",
    "\n",
    "# Plot the top 10 feature importances\n",
    "top_features = [feature_names[i] for i in top_10_indices]\n",
    "top_importances = importances_mean[top_10_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features, top_importances)\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Top 10 Feature Importances for Density Prediction')\n",
    "plt.show()\n",
    "\n",
    "# Print the column names of the top 10 features\n",
    "print(\"Column names of the top 10 features:\", top_10_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_non_zero_mask = enet_model_cv.best_estimator_.coef_ != 0\n",
    "en_train_Xsc = train_Xsc[:, en_non_zero_mask]\n",
    "en_test_Xsc = test_Xsc[:, en_non_zero_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "enet_model_cv.fit(en_train_Xsc, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial score: ', enet_model_cv.best_score_)\n",
    "print('Initial parameters: ', enet_model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_pred_en_refit = enet_model_cv.predict(en_test_Xsc)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_en = sklearn.metrics.r2_score(test_y, dy_pred_en_refit)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_en)\n",
    "\n",
    "RMSE_test_density_en = sklearn.metrics.mean_squared_error(test_y, dy_pred_en_refit, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(en_train_Xsc.shape)\n",
    "print(train_Xsc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "lasso_reg = Lasso(random_state=41)\n",
    "\n",
    "# lasso_hyperparam = {\n",
    "#     'alpha': np.arange(0.00, 1.1, 0.01)\n",
    "# } \n",
    "\n",
    "lasso_hyperparam = {\n",
    "    'alpha': np.logspace(-4, 2, 10),  # explore a range from 1e-4 to 1e2\n",
    "    'max_iter': [1000, 5000, 10000],\n",
    "    'tol': [1e-4, 1e-3, 1e-2],\n",
    "    'fit_intercept': [True, False],\n",
    "    'selection': ['cyclic', 'random']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lassoCV = GridSearchCV(estimator=lasso_reg,\n",
    "                       param_grid=lasso_hyperparam,\n",
    "                       scoring='r2',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lassoCV = BayesSearchCV(\n",
    "#     Lasso(), \n",
    "#     lasso_hyperparam,\n",
    "#     n_iter=32,\n",
    "#     cv=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lassoCV = GASearchCV(estimator = lasso_reg, \n",
    "#                                 cv=5,\n",
    "#                                 scoring= 'r2',  \n",
    "#                                 population_size=20,\n",
    "#                                 generations=35,\n",
    "#                                 param_grid = lasso_hyperparam,\n",
    "#                                 verbose = True,\n",
    "#                                 n_jobs = -1,\n",
    "#                                 keep_top_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "\n",
    "#lassoCV.fit(train_Xsc, train_y)\n",
    "#lassoCV.fit(X_train_pls, train_y)\n",
    "lassoCV.fit(X_train_pca, train_y)\n",
    "\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R2 score: ', lassoCV.best_score_)\n",
    "print('Best parameters: ', lassoCV.best_params_)\n",
    "best_lasso = lassoCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dy_pred_lasso = lassoCV.predict(test_Xsc)\n",
    "#dy_pred_lasso = lassoCV.predict(X_test_pls)\n",
    "dy_pred_lasso = lassoCV.predict(X_test_pca)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_lasso = sklearn.metrics.r2_score(test_y, dy_pred_lasso)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_lasso)\n",
    "\n",
    "RMSE_test_density_lasso = sklearn.metrics.mean_squared_error(test_y, dy_pred_lasso, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients = best_lasso.coef_\n",
    "\n",
    "# Get indices of nonzero coefficients\n",
    "nonzero_indices = np.nonzero(coefficients)[0]\n",
    "\n",
    "# Print nonzero coefficients\n",
    "print(\"Nonzero coefficients:\")\n",
    "for index in nonzero_indices:\n",
    "    coef_value = coefficients[index]\n",
    "    # Check if feature names are available\n",
    "    if hasattr(best_lasso, 'feature_names_in_'):\n",
    "        feature_name = best_lasso.feature_names_in_[index]\n",
    "        print(f\"{feature_name}: {coef_value:.4f}\")\n",
    "    else:\n",
    "        print(f\"Feature {index}: {coef_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error plot distribution of delta(y_test, y_pred)\n",
    "lasso_residuals = test_y - dy_pred_lasso\n",
    "\n",
    "pd.DataFrame({'Residuals': lasso_residuals}).hist(bins=25, figsize=(5,5), color=\"maroon\")\n",
    "\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Number of Test Datapoints')\n",
    "plt.title('Distribution of Residuals: Lasso Regression');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_non_zero_mask = lassoCV.best_estimator_.coef_ != 0\n",
    "lassor_train_Xsc = train_Xsc[:, lasso_non_zero_mask]\n",
    "lassor_test_Xsc = test_Xsc[:, lasso_non_zero_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "lassoCV.fit(lassor_train_Xsc, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial score: ', lassoCV.best_score_)\n",
    "print('Initial parameters: ', lassoCV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_pred_lasso = lassoCV.predict(lassor_test_Xsc)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_lasso = sklearn.metrics.r2_score(test_y, dy_pred_lasso)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_lasso)\n",
    "\n",
    "RMSE_test_density_lasso = sklearn.metrics.mean_squared_error(test_y, dy_pred_lasso, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lassor_train_Xsc.shape)\n",
    "print(train_Xsc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg = XGBRegressor()\n",
    "xg_params = {\n",
    "    'eta': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'subsample': [0.5, 0.7, 1.0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_random_cv = RandomizedSearchCV(estimator=xg,\n",
    "                                        param_distributions=xg_params,\n",
    "                                        n_iter =100,\n",
    "                                        scoring = 'r2',\n",
    "                                        cv = 3,\n",
    "                                        verbose =1,\n",
    "                                        n_jobs =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "\n",
    "#xg_random_cv.fit(train_Xsc, train_y)\n",
    "#xg_random_cv.fit(X_train_pls, train_y)\n",
    "xg_random_cv.fit(X_train_pca, train_y)\n",
    "\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial score: ', xg_random_cv.best_score_)\n",
    "print('Initial parameters: ', xg_random_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_grid_params = {\n",
    "    'eta': [0.001,0.01,0.1],\n",
    "    'n_estimators': [100,200,300],\n",
    "    'max_depth': [9,10,11],\n",
    "    'subsample': [0.5,0.6,0.7],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cv = GridSearchCV(estimator = xg, \n",
    "                    param_grid=xg_grid_params,\n",
    "                    scoring = 'r2', \n",
    "                    cv = 3, \n",
    "                    verbose = 1,\n",
    "                    n_jobs = -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_cv = BayesSearchCV(\n",
    "#     xg, \n",
    "#     xg_params,\n",
    "#     n_iter=100,\n",
    "#     cv=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xg_cv = GASearchCV(estimator = xg, \n",
    "#                                 cv=3,\n",
    "#                                 scoring= 'r2',  \n",
    "#                                 population_size=20,\n",
    "#                                 generations=35,\n",
    "#                                 param_grid = xg_params,\n",
    "#                                 verbose = True,\n",
    "#                                 n_jobs = -1,\n",
    "#                                 keep_top_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "\n",
    "#xg_cv.fit(train_Xsc, train_y)\n",
    "#xg_cv.fit(X_train_pls, train_y)\n",
    "xg_cv.fit(X_train_pca, train_y)\n",
    "\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improved score: ', xg_cv.best_score_)\n",
    "print('Improved parameters: ', xg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xg_reg = xg_cv.best_estimator_\n",
    "feature_names = pd.DataFrame(train_Xsc).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_importance = best_xg_reg.feature_importances_\n",
    "\n",
    "# Storing feature importance as a dataframe\n",
    "xg_feature_imp = pd.DataFrame(list(zip(feature_names, xg_importance)),\n",
    "               columns = ['Feature', 'Importance'])\n",
    "\n",
    "xg_feature_imp = xg_feature_imp.sort_values('Importance', ascending = False).reset_index(drop = True)\n",
    "\n",
    "# Bar plot\n",
    "xg_feature_imp_nonzero = xg_feature_imp[xg_feature_imp['Importance'] > 0.05]\n",
    "xg_fig = plt.figure(figsize=(10, 5))\n",
    "plt.barh(xg_feature_imp_nonzero['Feature'], xg_feature_imp_nonzero['Importance'], color = ['blue', 'green'])\n",
    "\n",
    "plt.xlabel(\"Importance\", fontsize = 12)\n",
    "plt.ylabel(\"Input Feature\", fontsize = 10)\n",
    "plt.title('Which features are the most important for density prediction?', fontsize = 12) \n",
    "plt.yticks(fontsize = 8) # fontsize of yticks\n",
    "plt.xticks(fontsize = 8) # fontsize of xticks\n",
    "\n",
    "#plt.tight_layout();\n",
    "#xg_fig.savefig('xg_aqueous_feature_imp.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dy_pred_xg = xg_cv.predict(test_Xsc)\n",
    "#dy_pred_xg = xg_cv.predict(X_test_pls)\n",
    "dy_pred_xg = xg_cv.predict(X_test_pca)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_xg = sklearn.metrics.r2_score(test_y, dy_pred_xg)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_xg)\n",
    "\n",
    "RMSE_test_density_xg = sklearn.metrics.mean_squared_error(test_y, dy_pred_xg, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_non_zero_mask = xg_importance != 0\n",
    "xg_train_Xsc = train_Xsc[:, xg_non_zero_mask]\n",
    "xg_test_Xsc = test_Xsc[:, xg_non_zero_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "xg_cv.fit(xg_train_Xsc, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial score: ', xg_cv.best_score_)\n",
    "print('Initial parameters: ', xg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_pred_xg = xg_cv.predict(xg_test_Xsc)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_xg = sklearn.metrics.r2_score(test_y, dy_pred_xg)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_xg)\n",
    "\n",
    "RMSE_test_density_xg = sklearn.metrics.mean_squared_error(test_y, dy_pred_xg, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xg_train_Xsc.shape)\n",
    "print(train_Xsc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 500, 1000],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],}\n",
    "rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_model_cv = RandomizedSearchCV(estimator=rf,\n",
    "                                        param_distributions=rf_params,\n",
    "                                        n_iter =100,\n",
    "                                        scoring = 'r2',\n",
    "                                        cv = 3,\n",
    "                                        verbose =1,\n",
    "                                        n_jobs =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "\n",
    "#rf_random_model_cv.fit(train_Xsc, train_y)\n",
    "#rf_random_model_cv.fit(X_train_pls, train_y)\n",
    "rf_random_model_cv.fit(X_train_pca, train_y)\n",
    "\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial score: ', rf_random_model_cv.best_score_)\n",
    "print('Initial parameters: ', rf_random_model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_params = {\n",
    "    'n_estimators': [400,500,1000],\n",
    "    'max_depth': [8,10,12],\n",
    "    'min_samples_split': [8,10,12],\n",
    "    'min_samples_leaf': [4,5,6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_cv = GridSearchCV(estimator = rf, \n",
    "                                param_grid = rf_grid_params, \n",
    "                                scoring= 'r2', \n",
    "                                cv = 3, \n",
    "                                verbose = 1,\n",
    "                                n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid_cv = BayesSearchCV(\n",
    "#     rf, rf_params,\n",
    "#     n_iter=200,\n",
    "#     cv=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_grid_cv = GASearchCV(estimator = rf, \n",
    "#                                 cv=3,\n",
    "#                                 scoring= 'r2',  \n",
    "#                                 population_size=20,\n",
    "#                                 generations=35,\n",
    "#                                 param_grid = rf_params,\n",
    "#                                 verbose = True,\n",
    "#                                 n_jobs = -1,\n",
    "#                                 keep_top_k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "\n",
    "#rf_grid_cv.fit(train_Xsc, train_y)  \n",
    "#rf_grid_cv.fit(X_train_pls, train_y)\n",
    "rf_grid_cv.fit(X_train_pca, train_y)\n",
    "\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improved score: ', rf_grid_cv.best_score_)\n",
    "print('Improved parameters: ', rf_grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_reg = rf_grid_cv.best_estimator_\n",
    "feature_names = pd.DataFrame(train_Xsc).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importance = best_rf_reg.feature_importances_\n",
    "\n",
    "# Storing feature importance as a dataframe\n",
    "rf_feature_imp = pd.DataFrame(list(zip(feature_names, rf_importance)),\n",
    "               columns = ['Feature', 'Importance'])\n",
    "\n",
    "# rf_feature_imp = pd.DataFrame(list(zip(X_train_pca.columns, rf_importance)),\n",
    "#                columns = ['Feature', 'Importance'])\n",
    "\n",
    "rf_feature_imp = rf_feature_imp.sort_values('Importance', ascending = False).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# Bar plot\n",
    "rf_feature_imp_nonzero = rf_feature_imp[rf_feature_imp['Importance'] > 0.01]\n",
    "rf_fig = plt.figure(figsize=(10, 5))\n",
    "plt.barh(rf_feature_imp['Feature'], rf_feature_imp['Importance'], color = ['blue', 'green'])\n",
    "\n",
    "plt.xlabel(\"Importance\", fontsize = 12)\n",
    "plt.ylabel(\"Input Feature\", fontsize = 12)\n",
    "plt.title('Which features are the most important for density prediction?', fontsize = 12) \n",
    "plt.yticks(fontsize = 8) # fontsize of yticks\n",
    "plt.xticks(fontsize = 8) # fontsize of xticks\n",
    "\n",
    "plt.tight_layout();\n",
    "rf_fig.savefig('rf_aqueous_feature_imp.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dy_pred_rf = rf_grid_cv.predict(test_Xsc)\n",
    "#dy_pred_rf = rf_grid_cv.predict(X_test_pls)\n",
    "dy_pred_rf = rf_grid_cv.predict(X_test_pca)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_rf = sklearn.metrics.r2_score(test_y, dy_pred_rf)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_rf)\n",
    "\n",
    "RMSE_test_density_rf = sklearn.metrics.mean_squared_error(test_y, dy_pred_rf, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_non_zero_mask = rf_importance != 0\n",
    "rf_train_Xsc = train_Xsc[:, rf_non_zero_mask]\n",
    "rf_test_Xsc = test_Xsc[:, rf_non_zero_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "rf_random_model_cv.fit(rf_train_Xsc, train_y)  \n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improved score: ', rf_grid_cv.best_score_)\n",
    "print('Improved parameters: ', rf_grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_pred_rf = rf_random_model_cv.predict(rf_test_Xsc)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_rf = sklearn.metrics.r2_score(test_y, dy_pred_rf)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_rf)\n",
    "\n",
    "RMSE_test_density_rf = sklearn.metrics.mean_squared_error(test_y, dy_pred_rf, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "kernels = ['linear', 'poly', 'rbf']\n",
    "\n",
    "svr_params = {\n",
    "    'kernel' : kernels,\n",
    "    'C': np.logspace(-3, 3, num=7), \n",
    "    'gamma': np.logspace(-3, 2, num=6)\n",
    "    }\n",
    "# svr_params = {\n",
    "#     'kernel' : Categorical(['linear', 'poly', 'rbf']),\n",
    "#     'C': Continuous(1e-3, 1e3, distribution='log-uniform'),  # Continuous values from 1e-3 to 1e3\n",
    "#     'gamma': Continuous(1e-3, 1e2, distribution='log-uniform') \n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svr_cv = GridSearchCV(estimator = svr, \n",
    "#                                 param_grid = svr_params, \n",
    "#                                 scoring= 'r2',\n",
    "#                                 cv=3,  \n",
    "#                                 verbose = 1,\n",
    "#                                 n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_cv = BayesSearchCV(\n",
    "    svr, \n",
    "    svr_params,\n",
    "    n_iter=100,\n",
    "    cv=3\n",
    ")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svr_cv = GASearchCV(estimator = svr, \n",
    "#                                 cv=3,\n",
    "#                                 scoring= 'r2',  \n",
    "#                                 population_size=20,\n",
    "#                                 generations=35,\n",
    "#                                 param_grid = svr_params,\n",
    "#                                 verbose = False,\n",
    "#                                 n_jobs = -1,\n",
    "#                                 keep_top_k=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 100.0, 'linear'] before, using random point [0.001, 100.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 100.0, 'linear'] before, using random point [0.1, 0.1, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.001, 10.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [1.0, 0.001, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [1000.0, 100.0, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [1.0, 1.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.01, 0.001, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [100.0, 1.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [1000.0, 10.0, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.001, 100.0, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.01, 1.0, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.1, 0.1, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [1.0, 0.1, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [1.0, 0.1, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [10.0, 100.0, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.1, 0.01, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [10.0, 1.0, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [10.0, 100.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [100.0, 1.0, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 10.0, 'linear'] before, using random point [100.0, 1.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [100.0, 0.01, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.1, 10.0, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.1, 0.1, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [1.0, 0.1, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.001, 0.1, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [0.001, 100.0, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.01, 'linear'] before, using random point [1000.0, 0.001, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.001, 'linear'] before, using random point [1.0, 0.1, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [0.01, 0.001, 'linear'] before, using random point [0.01, 0.001, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1.0, 0.001, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1000.0, 100.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1.0, 0.1, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.001, 100.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.01, 0.001, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1.0, 0.1, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.001, 10.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [10.0, 1.0, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1000.0, 0.1, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.1, 100.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.1, 0.001, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1.0, 1.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.01, 0.1, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.1, 0.001, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1.0, 10.0, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.1, 10.0, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [100.0, 0.01, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1000.0, 0.001, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.1, 0.001, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.1, 0.1, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [10.0, 10.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1000.0, 10.0, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.01, 100.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1000.0, 100.0, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1000.0, 0.001, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.01, 0.1, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [10.0, 0.01, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.01, 0.001, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [100.0, 0.01, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.1, 0.001, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1.0, 10.0, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.01, 10.0, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.001, 1.0, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.1, 0.001, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1000.0, 0.1, 'rbf']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [0.01, 0.1, 'linear']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1000.0, 0.1, 'poly']\n",
      "  warnings.warn(\n",
      "/Users/cameronlutz/anaconda3/lib/python3.11/site-packages/skopt/optimizer/optimizer.py:517: UserWarning: The objective has been evaluated at point [10.0, 0.001, 'rbf'] before, using random point [1000.0, 0.1, 'linear']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1062.9075329303741s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()            # Start Time\n",
    "\n",
    "#svr_cv.fit(train_Xsc, train_y)\n",
    "#svr_cv.fit(X_train_pls, train_y)\n",
    "svr_cv.fit(X_train_pca, train_y)\n",
    "\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved score:  0.3247468676391685\n",
      "OrderedDict([('C', 10.0), ('gamma', 0.001), ('kernel', 'rbf')])\n",
      "SVR(C=10.0, gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning \n",
    "print('Improved score: ', svr_cv.best_score_)\n",
    "print(svr_cv.best_params_) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "print(svr_cv.best_estimator_) \n",
    "\n",
    "best_svr = svr_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dy_pred_svr = svr_cv.predict(test_Xsc)\n",
    "#dy_pred_svr = svr_cv.predict(X_test_pls)\n",
    "dy_pred_svr = svr_cv.predict(X_test_pca)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_svr = sklearn.metrics.r2_score(test_y, dy_pred_svr)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_svr)\n",
    "\n",
    "RMSE_test_density_svr = sklearn.metrics.mean_squared_error(test_y, dy_pred_svr, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viscosity_pickle = open('visc_SVR_Full.pickle', 'wb') \n",
    "# pickle.dump(best_svr, viscosity_pickle) \n",
    "# viscosity_pickle.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "surface_pickle = open('surface_SVR_PCA.pickle', 'wb') \n",
    "pickle.dump(best_svr, surface_pickle) \n",
    "surface_pickle.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_residuals = test_y - dy_pred_svr\n",
    "\n",
    "pd.DataFrame({'Residuals': svr_residuals}).hist(bins=25, figsize=(12,8), color=\"maroon\")\n",
    "\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Number of Test Datapoints')\n",
    "plt.title('Distribution of SVR Residuals: Surface Tension');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if svr_cv.best_params_['kernel'] == 'linear':\n",
    "    svr_non_zero_mask = best_svr.coef_ != 0\n",
    "    svr_non_zero_mask = svr_non_zero_mask.ravel()  # Ensure it's a 1D array\n",
    "\n",
    "    svr_train_Xsc = train_Xsc[:, svr_non_zero_mask]\n",
    "    svr_test_Xsc = test_Xsc[:, svr_non_zero_mask]\n",
    "\n",
    "    # Refit the model using only the selected features\n",
    "    best_svr.fit(svr_train_Xsc, train_y)\n",
    "    dy_pred_svr_refit = best_svr.predict(svr_test_Xsc)\n",
    "    r2_density_svr_refit = r2_score(test_y, dy_pred_svr_refit)\n",
    "    RMSE_test_density_svr_refit = mean_squared_error(test_y, dy_pred_svr_refit, squared=False)\n",
    "\n",
    "    print('R-squared on Test Set after refit: %0.2f' % r2_density_svr_refit)\n",
    "    print('RMSE on Test Set after refit: %0.2f' % RMSE_test_density_svr_refit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_non_zero_mask = svr_cv.best_estimator_.coef_ != 0\n",
    "svr_train_Xsc = train_Xsc[:, svr_non_zero_mask]\n",
    "svr_test_Xsc = test_Xsc[:, svr_non_zero_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()            # Start Time\n",
    "svr_cv.fit(svr_train_Xsc, train_y)\n",
    "stop = time.time()             # End Time\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improved score: ', svr_cv.best_score_)\n",
    "print('Improved parameters: ', svr_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_pred_svr = svr_cv.predict(svr_test_Xsc)\n",
    "\n",
    "# evaluate the model on test set\n",
    "r2_density_svr = sklearn.metrics.r2_score(test_y, dy_pred_svr)\n",
    "print('R-squared on Test Set: %0.2f' %r2_density_svr)\n",
    "\n",
    "RMSE_test_density_svr = sklearn.metrics.mean_squared_error(test_y, dy_pred_svr, squared=False)\n",
    "print('RMSE on Test Set: %0.2f' %RMSE_test_density_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPIE Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define mapie regressor\n",
    "mapie = MapieRegressor(estimator = best_svr, # Prediction Model to use\n",
    "                       n_jobs = -1,\n",
    "                       agg_function = \"median\",\n",
    "                       random_state = 42)\n",
    "\n",
    "# Fit mapie regressor on training data\n",
    "mapie.fit(train_Xsc, train_y)\n",
    "\n",
    "alpha = 0.1 # for 90% target coverage\n",
    "\n",
    "# Use mapie.predict() to get predicted values and intervals\n",
    "y_test_pred, y_test_pis = mapie.predict(test_Xsc, alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted values\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Intervals\n",
    "y_test_pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing results in a dataframe\n",
    "predictions = test_y.to_frame()\n",
    "predictions.columns = ['Actual Value']\n",
    "predictions[\"Predicted Value\"] = y_test_pred.round(2)\n",
    "predictions[\"Lower Value\"] = y_test_pis.reshape(-1,2)[:,0].round(2)\n",
    "predictions[\"Upper Value\"] = y_test_pis.reshape(-1,2)[:,1].round(2)\n",
    "\n",
    "# Take a quick look\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"Error\"] = predictions[\"Predicted Value\"] - predictions[\"Actual Value\"]\n",
    "\n",
    "predictions[\"Error_upper\"] =   (predictions[\"Upper Value\"] - predictions[\"Predicted Value\"])\n",
    "predictions[\"Error_lower\"] =  -(predictions[\"Predicted Value\"] - predictions[\"Lower Value\"])\n",
    "\n",
    "# Sort by total interval width\n",
    "predictions[\"Interval_width\"] = predictions[\"Upper Value\"] - predictions[\"Lower Value\"]\n",
    "sorted_predictions = predictions.sort_values(by=['Interval_width']).reset_index(drop=True)\n",
    "sorted_predictions = sorted_predictions.drop(sorted_predictions.index[-1])\n",
    "sorted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "plt.plot(sorted_predictions[\"Error\"], 'o', markersize = 3, label = \"Error (y_pred - y_true)\")\n",
    "\n",
    "plt.fill_between(np.arange(len(sorted_predictions)),\n",
    "                 sorted_predictions[\"Error_lower\"],\n",
    "                 sorted_predictions[\"Error_upper\"],\n",
    "                 alpha=0.5, color=\"grey\", label = \"Prediction Interval\")\n",
    "\n",
    "ax.axline([0, 0], [1, 0], color = \"red\", linestyle='--', lw=2, zorder=3, label=\"y_true\")\n",
    "plt.xticks([])\n",
    "plt.xlim([0, len(sorted_predictions)])\n",
    "plt.ylabel(\"Errors\")\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of points outside of predicted interval\n",
    "sorted_predictions[\"is_outside_range\"] = 0\n",
    "sorted_predictions[\"is_outside_range\"] = sorted_predictions[\"is_outside_range\"].where((\n",
    "    (sorted_predictions[\"Error\"] < sorted_predictions[\"Error_upper\"]) & (sorted_predictions[\"Error\"] > sorted_predictions[\"Error_lower\"]) ),\n",
    "    other=1)\n",
    "\n",
    "print(round(100-(100/len(sorted_predictions))*sorted_predictions[\"is_outside_range\"].sum(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of prediction intervals that actually contain the ground truth value\n",
    "sorted_predictions[\"gt_within_PI\"] = 0\n",
    "sorted_predictions[\"gt_within_PI\"] = sorted_predictions[\"gt_within_PI\"].where((\n",
    "    (sorted_predictions[\"Actual Value\"] < sorted_predictions[\"Upper Value\"]) & (sorted_predictions[\"Actual Value\"] > sorted_predictions[\"Lower Value\"]) ),\n",
    "    other=1)\n",
    "\n",
    "print(round(100-(100/len(sorted_predictions))*sorted_predictions[\"gt_within_PI\"].sum(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-sort for plot\n",
    "sorted_predictions = predictions.sort_values(by=['Actual Value']).reset_index(drop=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "plt.plot(sorted_predictions[\"Actual Value\"], 'o', markersize=3, label=\"Actual Value\")\n",
    "\n",
    "plt.fill_between(np.arange(len(sorted_predictions)),\n",
    "                 sorted_predictions[\"Lower Value\"],\n",
    "                 sorted_predictions[\"Upper Value\"],\n",
    "                 alpha=0.5, color=\"grey\", label=\"Prediction Interval\")\n",
    "\n",
    "plt.xticks([],fontsize=14)\n",
    "plt.xlim([0, len(sorted_predictions)])\n",
    "plt.ylabel(\"True value\", fontsize=14)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(best_svr.predict, X_train_pca, feature_names=feature_names)\n",
    "\n",
    "# Calculate the minimum required evaluations\n",
    "num_features = X_train_pca.shape[1]\n",
    "min_evals = 2 * num_features + 1\n",
    "\n",
    "# Calculate SHAP values for the test set with increased max_evals\n",
    "shap_values = explainer(X_test_pca, max_evals=min_evals)\n",
    "\n",
    "# Plot SHAP values for the first prediction\n",
    "shap.summary_plot(shap_values, X_test_pca, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.waterfall(shap_values[0], max_display=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Global Model Interpretation\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance for SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pd.DataFrame(d_X).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "#perm_importance = permutation_importance(svr_cv, test_Xsc, test_y, n_repeats=30, random_state=42)\n",
    "perm_importance = permutation_importance(svr_cv, X_test_pca, test_y, n_repeats=30, random_state=42)\n",
    "\n",
    "# Extract importance scores and their standard deviations\n",
    "importances_mean = perm_importance.importances_mean\n",
    "importances_std = perm_importance.importances_std\n",
    "\n",
    "# Get the indices of the top 10 features by importance\n",
    "top_10_indices = np.argsort(importances_mean)[-10:][::-1]\n",
    "\n",
    "# Get the names of the top 10 features\n",
    "top_10_feature_names = [feature_names[i] for i in top_10_indices]\n",
    "\n",
    "# Print the top 10 features with their importance and confidence intervals\n",
    "print(\"Top 10 feature importances with confidence intervals:\")\n",
    "for i in top_10_indices:\n",
    "    if importances_mean[i] - 2 * importances_std[i] > 0:\n",
    "        print(f\"{feature_names[i]:<8} {importances_mean[i]:.3f} +/- {importances_std[i]:.3f}\")\n",
    "\n",
    "# Plot the top 10 feature importances\n",
    "top_features = [feature_names[i] for i in top_10_indices]\n",
    "top_importances = importances_mean[top_10_indices]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features, top_importances)\n",
    "plt.xlabel('Permutation Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Top 10 Feature Importances for Surface Tension Prediction')\n",
    "plt.show()\n",
    "\n",
    "# Print the column names of the top 10 features\n",
    "print(\"Column names of the top 10 features:\", top_10_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Molecule_Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>...</th>\n",
       "      <th>F08_C-C_</th>\n",
       "      <th>F08_C-N_</th>\n",
       "      <th>F08_C-O_</th>\n",
       "      <th>F08_O-O_</th>\n",
       "      <th>F09_C-C_</th>\n",
       "      <th>F09_C-O_</th>\n",
       "      <th>F09_O-O_</th>\n",
       "      <th>F10_C-C_</th>\n",
       "      <th>F10_C-O_</th>\n",
       "      <th>F10_O-O_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>273</td>\n",
       "      <td>Dipropylene glycol diacrylate</td>\n",
       "      <td>CC(COCC(C)OC(=O)C=C)OC(=O)C=C</td>\n",
       "      <td>242.30</td>\n",
       "      <td>6.923</td>\n",
       "      <td>20.315</td>\n",
       "      <td>35.589</td>\n",
       "      <td>21.125</td>\n",
       "      <td>39.784</td>\n",
       "      <td>0.580</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274</td>\n",
       "      <td>Ethoxylated 3 EO trimethylolpropane triacrylate</td>\n",
       "      <td>CCC(COCCOC(=O)C=C)(COCCOC(=O)C=C)COCCOC(=O)C=C</td>\n",
       "      <td>428.53</td>\n",
       "      <td>6.912</td>\n",
       "      <td>35.862</td>\n",
       "      <td>63.083</td>\n",
       "      <td>37.273</td>\n",
       "      <td>70.528</td>\n",
       "      <td>0.578</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275</td>\n",
       "      <td>Ethoxylated 5 EO pentaerythritol tetraacrylate</td>\n",
       "      <td>C=CC(=O)OCC(COC(=O)C=C)(COC(=O)C=C)COC(=O)C=C</td>\n",
       "      <td>352.37</td>\n",
       "      <td>7.830</td>\n",
       "      <td>27.986</td>\n",
       "      <td>46.454</td>\n",
       "      <td>28.250</td>\n",
       "      <td>50.827</td>\n",
       "      <td>0.622</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276</td>\n",
       "      <td>Dipentaerythritol hexaacrylate</td>\n",
       "      <td>C=CC(=O)OCC(COCC(COC(=O)C=C)(COC(=O)C=C)COC(=O...</td>\n",
       "      <td>578.62</td>\n",
       "      <td>7.715</td>\n",
       "      <td>46.248</td>\n",
       "      <td>77.276</td>\n",
       "      <td>46.852</td>\n",
       "      <td>84.781</td>\n",
       "      <td>0.617</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>277</td>\n",
       "      <td>Octyl Acrylate</td>\n",
       "      <td>CCCCCCCCOC(=O)C=C</td>\n",
       "      <td>184.31</td>\n",
       "      <td>5.585</td>\n",
       "      <td>17.698</td>\n",
       "      <td>32.491</td>\n",
       "      <td>19.523</td>\n",
       "      <td>37.571</td>\n",
       "      <td>0.536</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                    Molecule_Name  \\\n",
       "0  273                    Dipropylene glycol diacrylate   \n",
       "1  274  Ethoxylated 3 EO trimethylolpropane triacrylate   \n",
       "2  275   Ethoxylated 5 EO pentaerythritol tetraacrylate   \n",
       "3  276                   Dipentaerythritol hexaacrylate   \n",
       "4  277                                   Octyl Acrylate   \n",
       "\n",
       "                                              SMILES      MW    AMW      Sv  \\\n",
       "0                      CC(COCC(C)OC(=O)C=C)OC(=O)C=C  242.30  6.923  20.315   \n",
       "1     CCC(COCCOC(=O)C=C)(COCCOC(=O)C=C)COCCOC(=O)C=C  428.53  6.912  35.862   \n",
       "2      C=CC(=O)OCC(COC(=O)C=C)(COC(=O)C=C)COC(=O)C=C  352.37  7.830  27.986   \n",
       "3  C=CC(=O)OCC(COCC(COC(=O)C=C)(COC(=O)C=C)COC(=O...  578.62  7.715  46.248   \n",
       "4                                  CCCCCCCCOC(=O)C=C  184.31  5.585  17.698   \n",
       "\n",
       "       Se      Sp      Si     Mv  ...  F08_C-C_  F08_C-N_  F08_C-O_  F08_O-O_  \\\n",
       "0  35.589  21.125  39.784  0.580  ...         5         0         4         2   \n",
       "1  63.083  37.273  70.528  0.578  ...        18         0        21         0   \n",
       "2  46.454  28.250  50.827  0.622  ...        18         0        12         6   \n",
       "3  77.276  46.852  84.781  0.617  ...        48         0        18        15   \n",
       "4  32.491  19.523  37.571  0.536  ...         3         0         2         0   \n",
       "\n",
       "   F09_C-C_  F09_C-O_  F09_O-O_  F10_C-C_  F10_C-O_  F10_O-O_  \n",
       "0         4         4         0         3         2         1  \n",
       "1        18        15         6        15        12         3  \n",
       "2        12        12         0         6         0         0  \n",
       "3        36        48         0        33        18        18  \n",
       "4         3         1         0         2         1         0  \n",
       "\n",
       "[5 rows x 1061 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maywheather = pd.read_excel('FINAL-predictionset.xlsx')\n",
    "maywheather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MW</th>\n",
       "      <th>AMW</th>\n",
       "      <th>Sv</th>\n",
       "      <th>Se</th>\n",
       "      <th>Sp</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mv</th>\n",
       "      <th>Me</th>\n",
       "      <th>Mp</th>\n",
       "      <th>Mi</th>\n",
       "      <th>...</th>\n",
       "      <th>F08_C-C_</th>\n",
       "      <th>F08_C-N_</th>\n",
       "      <th>F08_C-O_</th>\n",
       "      <th>F08_O-O_</th>\n",
       "      <th>F09_C-C_</th>\n",
       "      <th>F09_C-O_</th>\n",
       "      <th>F09_O-O_</th>\n",
       "      <th>F10_C-C_</th>\n",
       "      <th>F10_C-O_</th>\n",
       "      <th>F10_O-O_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242.30</td>\n",
       "      <td>6.923</td>\n",
       "      <td>20.315</td>\n",
       "      <td>35.589</td>\n",
       "      <td>21.125</td>\n",
       "      <td>39.784</td>\n",
       "      <td>0.580</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.604</td>\n",
       "      <td>1.137</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>428.53</td>\n",
       "      <td>6.912</td>\n",
       "      <td>35.862</td>\n",
       "      <td>63.083</td>\n",
       "      <td>37.273</td>\n",
       "      <td>70.528</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.601</td>\n",
       "      <td>1.138</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>352.37</td>\n",
       "      <td>7.830</td>\n",
       "      <td>27.986</td>\n",
       "      <td>46.454</td>\n",
       "      <td>28.250</td>\n",
       "      <td>50.827</td>\n",
       "      <td>0.622</td>\n",
       "      <td>1.032</td>\n",
       "      <td>0.628</td>\n",
       "      <td>1.129</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>578.62</td>\n",
       "      <td>7.715</td>\n",
       "      <td>46.248</td>\n",
       "      <td>77.276</td>\n",
       "      <td>46.852</td>\n",
       "      <td>84.781</td>\n",
       "      <td>0.617</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.130</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>184.31</td>\n",
       "      <td>5.585</td>\n",
       "      <td>17.698</td>\n",
       "      <td>32.491</td>\n",
       "      <td>19.523</td>\n",
       "      <td>37.571</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.592</td>\n",
       "      <td>1.139</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1058 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MW    AMW      Sv      Se      Sp      Si     Mv     Me     Mp     Mi  \\\n",
       "0  242.30  6.923  20.315  35.589  21.125  39.784  0.580  1.017  0.604  1.137   \n",
       "1  428.53  6.912  35.862  63.083  37.273  70.528  0.578  1.017  0.601  1.138   \n",
       "2  352.37  7.830  27.986  46.454  28.250  50.827  0.622  1.032  0.628  1.129   \n",
       "3  578.62  7.715  46.248  77.276  46.852  84.781  0.617  1.030  0.625  1.130   \n",
       "4  184.31  5.585  17.698  32.491  19.523  37.571  0.536  0.985  0.592  1.139   \n",
       "\n",
       "   ...  F08_C-C_  F08_C-N_  F08_C-O_  F08_O-O_  F09_C-C_  F09_C-O_  F09_O-O_  \\\n",
       "0  ...         5         0         4         2         4         4         0   \n",
       "1  ...        18         0        21         0        18        15         6   \n",
       "2  ...        18         0        12         6        12        12         0   \n",
       "3  ...        48         0        18        15        36        48         0   \n",
       "4  ...         3         0         2         0         3         1         0   \n",
       "\n",
       "   F10_C-C_  F10_C-O_  F10_O-O_  \n",
       "0         3         2         1  \n",
       "1        15        12         3  \n",
       "2         6         0         0  \n",
       "3        33        18        18  \n",
       "4         2         1         0  \n",
       "\n",
       "[5 rows x 1058 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maywheather = maywheather.drop(columns=['ID','Molecule_Name','SMILES'])\n",
    "test_X = maywheather\n",
    "test_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtest_Xsc = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain 95% of the variance\n",
    "test_Xsc = pca.transform(qtest_Xsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('density_EN_Full.pickle', 'rb') as density_pickle_pred:\n",
    "    density_prediction_model = pickle.load(density_pickle_pred)\n",
    "\n",
    "# Make predictions using the model\n",
    "d_predictions = density_prediction_model.predict(test_Xsc)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "d_predictions_df = pd.DataFrame(d_predictions, columns=['Predicted Density'])\n",
    "\n",
    "# Optionally, combine with the original test data for reference\n",
    "d_final_df = pd.concat([test_X.reset_index(drop=True), d_predictions_df], axis=1)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(d_final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('visc_SVR_Full.pickle', 'rb') as viscosity_pickle_pred:\n",
    "    viscosity_prediction_model = pickle.load(viscosity_pickle_pred)\n",
    "\n",
    "# Make predictions using the model\n",
    "v_predictions = viscosity_prediction_model.predict(test_Xsc)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "v_predictions_df = pd.DataFrame(v_predictions, columns=['Predicted Viscosity'])\n",
    "\n",
    "# Optionally, combine with the original test data for reference\n",
    "v_final_df = pd.concat([test_X.reset_index(drop=True), v_predictions_df], axis=1)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(v_final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MW    AMW      Sv      Se      Sp      Si     Mv     Me     Mp     Mi  \\\n",
      "0  242.30  6.923  20.315  35.589  21.125  39.784  0.580  1.017  0.604  1.137   \n",
      "1  428.53  6.912  35.862  63.083  37.273  70.528  0.578  1.017  0.601  1.138   \n",
      "2  352.37  7.830  27.986  46.454  28.250  50.827  0.622  1.032  0.628  1.129   \n",
      "3  578.62  7.715  46.248  77.276  46.852  84.781  0.617  1.030  0.625  1.130   \n",
      "4  184.31  5.585  17.698  32.491  19.523  37.571  0.536  0.985  0.592  1.139   \n",
      "\n",
      "   ...  F08_C-N_  F08_C-O_  F08_O-O_  F09_C-C_  F09_C-O_  F09_O-O_  F10_C-C_  \\\n",
      "0  ...         0         4         2         4         4         0         3   \n",
      "1  ...         0        21         0        18        15         6        15   \n",
      "2  ...         0        12         6        12        12         0         6   \n",
      "3  ...         0        18        15        36        48         0        33   \n",
      "4  ...         0         2         0         3         1         0         2   \n",
      "\n",
      "   F10_C-O_  F10_O-O_  Predicted Surface Tension  \n",
      "0         2         1                  36.716097  \n",
      "1        12         3                  37.307976  \n",
      "2         0         0                  37.314377  \n",
      "3        18        18                  37.314392  \n",
      "4         1         0                  28.931766  \n",
      "\n",
      "[5 rows x 1059 columns]\n"
     ]
    }
   ],
   "source": [
    "with open('surface_SVR_PCA.pickle', 'rb') as surface_pickle_pred:\n",
    "    surface_prediction_model = pickle.load(surface_pickle_pred)\n",
    "\n",
    "# Make predictions using the model\n",
    "s_predictions = surface_prediction_model.predict(test_Xsc)\n",
    "\n",
    "# Create a DataFrame with the predictions\n",
    "s_predictions_df = pd.DataFrame(s_predictions, columns=['Predicted Surface Tension'])\n",
    "\n",
    "# Optionally, combine with the original test data for reference\n",
    "s_final_df = pd.concat([test_X.reset_index(drop=True), s_predictions_df], axis=1)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(s_final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapie.regression import MapieRegressor\n",
    "# density_prediction_model\n",
    "# viscosity_prediction_model\n",
    "# surface_prediction_model\n",
    "\n",
    "# Define mapie regressor\n",
    "#mapie = MapieRegressor(estimator = density_prediction_model, # Prediction Model to use\n",
    "#mapie = MapieRegressor(estimator = viscosity_prediction_model,\n",
    "mapie = MapieRegressor(estimator = surface_prediction_model,                    \n",
    "                       n_jobs = -1,\n",
    "                       agg_function = \"median\",\n",
    "                       random_state = 42)\n",
    "\n",
    "# Fit mapie regressor on training data\n",
    "#mapie.fit(test_Xsc, d_predictions) \n",
    "#mapie.fit(test_Xsc, v_predictions) \n",
    "mapie.fit(test_Xsc, s_predictions) \n",
    "\n",
    "alpha = 0.1 # for 90% target coverage\n",
    "\n",
    "# Use mapie.predict() to get predicted values and intervals\n",
    "y_test_pred, y_test_pis = mapie.predict(test_Xsc, alpha = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.61595683, 37.2079704 , 37.21410981, 37.21465132, 29.03196736,\n",
       "       28.95221304, 30.1844316 , 30.18428312, 30.80457717, 31.33559595,\n",
       "       31.8618215 , 32.37245862, 33.3089074 , 32.9872712 , 35.65426963,\n",
       "       30.09684001, 32.4529778 , 33.37986564, 36.39867829, 36.56979462,\n",
       "       32.90217513, 35.62169529, 36.42649853, 31.38874103, 32.7767699 ,\n",
       "       36.12647787, 37.30373607, 32.21939771, 32.19700902, 30.49859751,\n",
       "       35.73352336, 37.03438834, 37.37428558, 37.16879187, 35.45820566,\n",
       "       36.8809405 , 37.04145454, 36.99642429, 36.80200731, 40.45710502,\n",
       "       35.56116796, 35.21215384, 31.2368502 , 45.1854161 , 38.6308184 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicted values\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[33.69580728],\n",
       "        [39.53712235]],\n",
       "\n",
       "       [[34.23526772],\n",
       "        [40.12905134]],\n",
       "\n",
       "       [[34.24210586],\n",
       "        [40.13535916]],\n",
       "\n",
       "       [[34.29346016],\n",
       "        [40.13477523]],\n",
       "\n",
       "       [[26.14835588],\n",
       "        [31.95221641]],\n",
       "\n",
       "       [[26.03130056],\n",
       "        [31.87261563]],\n",
       "\n",
       "       [[27.26371503],\n",
       "        [33.10503011]],\n",
       "\n",
       "       [[27.26202016],\n",
       "        [33.07709758]],\n",
       "\n",
       "       [[27.88376473],\n",
       "        [33.68760463]],\n",
       "\n",
       "       [[28.41479218],\n",
       "        [34.25610725]],\n",
       "\n",
       "       [[28.94179694],\n",
       "        [34.78311201]],\n",
       "\n",
       "       [[29.45209106],\n",
       "        [35.29340613]],\n",
       "\n",
       "       [[30.38522257],\n",
       "        [36.24285248]],\n",
       "\n",
       "       [[30.10427936],\n",
       "        [35.90777116]],\n",
       "\n",
       "       [[32.68153431],\n",
       "        [38.53791068]],\n",
       "\n",
       "       [[27.17621574],\n",
       "        [33.07008819]],\n",
       "\n",
       "       [[29.53214021],\n",
       "        [35.37345528]],\n",
       "\n",
       "       [[30.45897923],\n",
       "        [36.3002943 ]],\n",
       "\n",
       "       [[33.42586803],\n",
       "        [39.28197863]],\n",
       "\n",
       "       [[33.64994085],\n",
       "        [39.49125592]],\n",
       "\n",
       "       [[29.92946474],\n",
       "        [35.78516387]],\n",
       "\n",
       "       [[32.64963918],\n",
       "        [38.59510892]],\n",
       "\n",
       "       [[33.45431575],\n",
       "        [39.3099874 ]],\n",
       "\n",
       "       [[28.41630809],\n",
       "        [34.30944501]],\n",
       "\n",
       "       [[29.85561727],\n",
       "        [35.69693235]],\n",
       "\n",
       "       [[33.2059225 ],\n",
       "        [39.04723758]],\n",
       "\n",
       "       [[34.29540228],\n",
       "        [40.13671736]],\n",
       "\n",
       "       [[29.29850531],\n",
       "        [35.13982039]],\n",
       "\n",
       "       [[29.23903209],\n",
       "        [35.12735732]],\n",
       "\n",
       "       [[27.5777223 ],\n",
       "        [33.41903737]],\n",
       "\n",
       "       [[32.81275605],\n",
       "        [38.65407112]],\n",
       "\n",
       "       [[34.11396556],\n",
       "        [39.95528063]],\n",
       "\n",
       "       [[34.45376825],\n",
       "        [40.29508332]],\n",
       "\n",
       "       [[34.24788937],\n",
       "        [40.14135801]],\n",
       "\n",
       "       [[32.53786193],\n",
       "        [38.43071928]],\n",
       "\n",
       "       [[33.96053976],\n",
       "        [39.76446432]],\n",
       "\n",
       "       [[33.7237554 ],\n",
       "        [39.96184039]],\n",
       "\n",
       "       [[34.01780179],\n",
       "        [39.85911687]],\n",
       "\n",
       "       [[33.82915758],\n",
       "        [39.69473176]],\n",
       "\n",
       "       [[33.14361148],\n",
       "        [42.10641364]],\n",
       "\n",
       "       [[32.58813115],\n",
       "        [38.48200139]],\n",
       "\n",
       "       [[31.3005468 ],\n",
       "        [38.09486937]],\n",
       "\n",
       "       [[27.96859664],\n",
       "        [35.4399273 ]],\n",
       "\n",
       "       [[35.174154  ],\n",
       "        [46.32679526]],\n",
       "\n",
       "       [[34.79347229],\n",
       "        [41.51409092]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Intervals\n",
    "y_test_pis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = y_test_pred.flatten()\n",
    "lower_bounds = y_test_pis[:, 0].flatten()\n",
    "upper_bounds = y_test_pis[:, 1].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing results in a dataframe\n",
    "predictions = pd.DataFrame({\n",
    "    'Lower Bound': lower_bounds.round(2),\n",
    "    'Predicted Value': y_test_pred.round(2),\n",
    "    'Upper Bound': upper_bounds.round(2)\n",
    "})\n",
    "# Take a quick look\n",
    "predictions\n",
    "#predictions.to_excel('density-ints.xlsx', index=False)\n",
    "#predictions.to_excel('visc-ints.xlsx', index=False)\n",
    "predictions.to_excel('surface-ints.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISC MAPIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[\"Error\"] = predictions[\"Predicted Value\"] - predictions[\"Actual Value\"]\n",
    "\n",
    "predictions[\"Error_upper\"] =   (predictions[\"Upper Value\"] - predictions[\"Predicted Value\"])\n",
    "predictions[\"Error_lower\"] =  -(predictions[\"Predicted Value\"] - predictions[\"Lower Value\"])\n",
    "\n",
    "# Sort by total interval width\n",
    "predictions[\"Interval_width\"] = predictions[\"Upper Value\"] - predictions[\"Lower Value\"]\n",
    "sorted_predictions = predictions.sort_values(by=['Interval_width']).reset_index(drop=True)\n",
    "sorted_predictions = sorted_predictions.drop(sorted_predictions.index[-1])\n",
    "sorted_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "plt.plot(sorted_predictions[\"Error\"], 'o', markersize = 3, label = \"Error (y_pred - y_true)\")\n",
    "\n",
    "plt.fill_between(np.arange(len(sorted_predictions)),\n",
    "                 sorted_predictions[\"Error_lower\"],\n",
    "                 sorted_predictions[\"Error_upper\"],\n",
    "                 alpha=0.5, color=\"grey\", label = \"Prediction Interval\")\n",
    "\n",
    "ax.axline([0, 0], [1, 0], color = \"red\", linestyle='--', lw=2, zorder=3, label=\"y_true\")\n",
    "plt.xticks([])\n",
    "plt.xlim([0, len(sorted_predictions)])\n",
    "plt.ylabel(\"Errors\")\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of points outside of predicted interval\n",
    "sorted_predictions[\"is_outside_range\"] = 0\n",
    "sorted_predictions[\"is_outside_range\"] = sorted_predictions[\"is_outside_range\"].where((\n",
    "    (sorted_predictions[\"Error\"] < sorted_predictions[\"Error_upper\"]) & (sorted_predictions[\"Error\"] > sorted_predictions[\"Error_lower\"]) ),\n",
    "    other=1)\n",
    "\n",
    "print(round(100-(100/len(sorted_predictions))*sorted_predictions[\"is_outside_range\"].sum(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of prediction intervals that actually contain the ground truth value\n",
    "sorted_predictions[\"gt_within_PI\"] = 0\n",
    "sorted_predictions[\"gt_within_PI\"] = sorted_predictions[\"gt_within_PI\"].where((\n",
    "    (sorted_predictions[\"Actual Value\"] < sorted_predictions[\"Upper Value\"]) & (sorted_predictions[\"Actual Value\"] > sorted_predictions[\"Lower Value\"]) ),\n",
    "    other=1)\n",
    "\n",
    "print(round(100-(100/len(sorted_predictions))*sorted_predictions[\"gt_within_PI\"].sum(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-sort for plot\n",
    "sorted_predictions = predictions.sort_values(by=['Actual Value']).reset_index(drop=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 9))\n",
    "\n",
    "plt.plot(sorted_predictions[\"Actual Value\"], 'o', markersize=3, label=\"Actual Value\")\n",
    "\n",
    "plt.fill_between(np.arange(len(sorted_predictions)),\n",
    "                 sorted_predictions[\"Lower Value\"],\n",
    "                 sorted_predictions[\"Upper Value\"],\n",
    "                 alpha=0.5, color=\"grey\", label=\"Prediction Interval\")\n",
    "\n",
    "plt.xticks([],fontsize=14)\n",
    "plt.xlim([0, len(sorted_predictions)])\n",
    "plt.ylabel(\"True value\", fontsize=14)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
